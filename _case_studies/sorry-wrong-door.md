---
layout: case_study_v2
title: "Sorry, Wrong Door"
subtitle: "Early LLM experiment with adaptive difficulty"
project_type: "Lying Narrator"
client: ""
summary: "An early LLM-powered game using a lying narrator and an adaptive difficulty engine that adjusts in real-time"
date: 2022-11-20
industry: "Interactive Gaming / AI Research"
tags: ["Deception Engine", "Adaptive Difficulty", "Procedural Doors"]
series: "AI That Lives"
series_order: 5
---

## The Challenge

Build one of the first LLM-powered games—with adaptive difficulty and a lying narrator—when almost no one knew it was possible.

## The Solution

A deceptively simple door-choice game where an AI narrator provides hints about the correct path while lying 25% of the time, with a difficulty system that automatically adjusts "obviousness levels" based on real-time player success rates.

---

## Adaptive Intelligence: AI That Learns from Player Behavior

### Core Mechanics

**Binary choice system**: Players choose between two doors to progress

**Controlled deception**: AI lies 25% of the time, players know this creates trust/doubt tension

**Hint generation**: LLM creates room descriptions containing clues about the correct door

**Real-time difficulty adjustment**: System tracks success rates and modifies "obviousness level" to maintain target success percentages

### Innovation in Early LLM Era

**Pioneering application**: Built when first-generation LLMs were brand new, before most practitioners understood prompt engineering for games

**Dynamic prompt modification**: AI receives different instructions based on room performance data

**Behavioral feedback loops**: Player success/failure directly influences AI generation parameters

---

## Game Design Psychology: Trust and Deception

### Player Experience Innovation

**Known unreliable narrator**: Players aware of 25% lie rate creates engaging psychological tension

**Adaptive challenge**: Difficulty automatically adjusts to player skill, maintaining engagement without frustration

**Meta-gaming elements**: Players must judge AI believability and hint obviousness

### What Actually Happened

**Players developed strategies** for detecting AI lies through linguistic patterns

**Difficulty system successfully maintained** 65-75% success rates across different player skill levels

**Emergent trust dynamics** as players learned to calibrate their confidence in AI hints

**Foundational insights** into prompt engineering for consistent game mechanics

---

## Why This Matters for Marketing Technology

### Foundational Applications

**Adaptive content difficulty**: AI that adjusts messaging complexity based on audience engagement

**Controlled narrative tension**: Systems that balance truth and intrigue in brand storytelling

**Real-time personalization**: Content that adapts based on user behavior patterns

**Trust calibration**: Understanding how users develop confidence in AI-generated content

---

## Key Insights

- **Early LLM experiments** revealed fundamental principles still used today
- **Adaptive difficulty systems** can maintain engagement across skill levels
- **Controlled deception** creates engaging psychological dynamics
- **Real-time feedback loops** enable AI systems that improve during use

**The result**: A foundational experiment in adaptive AI game design that demonstrated core principles of dynamic difficulty adjustment and controlled AI deception before these became standard practices.