---
layout: case_study_default
title: "Sorry, Wrong Door"
subtitle: "Early LLM experiment with adaptive difficulty"
project_type: "Lying Narrator"
client: ""
summary: "An early LLM-powered game using a lying narrator and an adaptive difficulty engine that adjusts in real-time"
date: 2022-11-20
industry: "Interactive Gaming / AI Research"
tags: ["Deception Engine", "Adaptive Difficulty", "Procedural Doors"]
series: "AI That Lives"
series_order: 5
---

## The Challenge

Build one of the first LLM-powered games—with adaptive difficulty and a lying narrator—when almost no one knew it was possible.

## The Solution

A deceptively simple door-choice game where an AI narrator provides hints about the correct path while lying 25% of the time, with a difficulty system that automatically adjusts "obviousness levels" based on real-time player success rates.

---

## Adaptive Intelligence: AI That Learns from Player Behavior

<div class="feature-section" markdown="1">

### Core Mechanics
{: .feature-title}

- **Binary choice system**: Players choose between two doors to progress
- **Controlled deception**: AI lies 25% of the time, players know this creates trust/doubt tension
- **Hint generation**: LLM creates room descriptions containing clues about the correct door
- **Real-time difficulty adjustment**: System tracks success rates and modifies "obviousness level" to maintain target success percentages

</div>

<div class="feature-section" markdown="1">

### Innovation in Early LLM Era
{: .feature-title}

- **Pioneering application**: Built when first-generation LLMs were brand new, before most practitioners understood prompt engineering for games
- **Dynamic prompt modification**: AI receives different instructions based on room performance data
- **Behavioral feedback loops**: Player success/failure directly influences AI generation parameters

</div>

---

## Game Design Psychology: Trust and Deception

<div class="feature-section" markdown="1">

### Player Experience Innovation
{: .feature-title}

- **Known unreliable narrator**: Players aware of 25% lie rate creates engaging psychological tension
- **Adaptive challenge**: Difficulty automatically adjusts to player skill, maintaining engagement without frustration
- **Meta-gaming elements**: Players must judge AI believability and hint obviousness

</div>

<div class="feature-section" markdown="1">

### What Actually Happened
{: .feature-title}

- **Players developed strategies** for detecting AI lies through linguistic patterns
- **Difficulty system successfully maintained** 65-75% success rates across different player skill levels
- **Emergent trust dynamics** as players learned to calibrate their confidence in AI hints
- **Foundational insights** into prompt engineering for consistent game mechanics

</div>

---

## Why This Matters for Marketing Technology

<div class="feature-section" markdown="1">

### Foundational Applications
{: .feature-title}

- **Adaptive content difficulty**: AI that adjusts messaging complexity based on audience engagement
- **Controlled narrative tension**: Systems that balance truth and intrigue in brand storytelling
- **Real-time personalization**: Content that adapts based on user behavior patterns
- **Trust calibration**: Understanding how users develop confidence in AI-generated content

</div>

---

## Key Insights

<div class="feature-section" markdown="1">

### Key Insights
{: .feature-title}

- **Early LLM experiments** revealed fundamental principles still used today
- **Adaptive difficulty systems** can maintain engagement across skill levels
- **Controlled deception** creates engaging psychological dynamics
- **Real-time feedback loops** enable AI systems that improve during use

**The result**: A foundational experiment in adaptive AI game design that demonstrated core principles of dynamic difficulty adjustment and controlled AI deception before these became standard practices.

</div>